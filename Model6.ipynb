{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import transformers\n",
    "import nltk\n",
    "from keyphrase_vectorizers import KeyphraseCountVectorizer\n",
    "from pdfminer.high_level import extract_text\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf(filename):\n",
    "    text = extract_text(filename)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_gutenberg_parts(paragraphs):\n",
    "    # Define regular expressions to match Gutenberg-related parts\n",
    "    gutenberg_regex = r'[Gg][Uu][Tt][Ee][Nn][Bb][Ee][Rr][Gg]'\n",
    "\n",
    "    # Remove Gutenberg-related parts from each paragraph\n",
    "    filtered_paragraphs = []\n",
    "    for paragraph in paragraphs:\n",
    "        if not re.search(gutenberg_regex, paragraph):\n",
    "            filtered_paragraphs.append(paragraph)\n",
    "\n",
    "    return filtered_paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foreword_split(text):\n",
    "    foreword_regex = r'[Ff][Oo][Rr][Ee][Ww][Oo][Rr][Dd]'\n",
    "    if re.search(foreword_regex, text) != None:\n",
    "        return text.split(re.search(foreword_regex, text).group(0))[1]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitParagraph(paragraphs):\n",
    "    i = 0\n",
    "    while i < len(paragraphs):\n",
    "        current_paragraph = paragraphs[i]\n",
    "        current_paragraph_word_count = len(current_paragraph.split())\n",
    "\n",
    "        if current_paragraph_word_count <= 50:\n",
    "            # Check the previous paragraph\n",
    "            if i > 0 and i < len(paragraphs) - 1:\n",
    "                if len(paragraphs[i-1].split()) <= len(paragraphs[i+1].split()):\n",
    "                    merged_paragraph = paragraphs[i-1] + \"\\n\" + current_paragraph\n",
    "                    paragraphs[i-1] = merged_paragraph\n",
    "                    del paragraphs[i]\n",
    "                    continue\n",
    "                else:\n",
    "                    merged_paragraph = current_paragraph + \"\\n\" + paragraphs[i+1]\n",
    "                    paragraphs[i+1] = merged_paragraph\n",
    "                    del paragraphs[i]\n",
    "                    continue\n",
    "            elif i == 0:\n",
    "                merged_paragraph = current_paragraph + \"\\n\" + paragraphs[1]\n",
    "                paragraphs[1] = merged_paragraph\n",
    "                del paragraphs[0]\n",
    "                continue\n",
    "            elif i == len(paragraphs) - 1:\n",
    "                merged_paragraph = paragraphs[i-1] + \"\\n\" + current_paragraph\n",
    "                paragraphs[i-1] = merged_paragraph\n",
    "                del paragraphs[i]\n",
    "                continue\n",
    "\n",
    "\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findRelevantParagraphs(paragraphs, keywords,text,model,stop_words,n = 10,relevant_paragraphs = []):\n",
    "    for paragraph in paragraphs:\n",
    "        count_keywords = 0\n",
    "        for keyword in keywords:\n",
    "            if keyword[0] in paragraph:\n",
    "                count_keywords += 1\n",
    "        if count_keywords >= 2 and paragraph not in relevant_paragraphs:\n",
    "            relevant_paragraphs.append(paragraph)\n",
    "    \n",
    "    if(len(relevant_paragraphs) < 10):        \n",
    "        keywords = model.extract_keywords(text, keyphrase_ngram_range=(1,1), diversity=0.2,top_n=n+5,stop_words=stop_words,use_maxsum=True,use_mmr=True)\n",
    "        findRelevantParagraphs(paragraphs,keywords,text,model,stop_words,n+5,relevant_paragraphs)\n",
    "    return relevant_paragraphs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting rid of the Gutenberg parts\n",
    "text = extract_pdf('pdfs\\\\The_WonderfulWizardofOz.pdf')\n",
    "paragraphs = text.split(\"\\n\\n\")\n",
    "splitParagraph(paragraphs)\n",
    "paragraphs = filter_gutenberg_parts(paragraphs)\n",
    "text = '\\n\\n'.join(paragraphs)\n",
    "text = foreword_split(text)\n",
    "paragraphs = text.split(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\n",
    "    \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"ain\", \"all\", \"am\", \"an\", \"and\", \"any\", \n",
    "    \"are\", \"aren\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \n",
    "    \"both\", \"but\", \"by\", \"can\", \"couldn\", \"d\", \"did\", \"didn\", \"do\", \"does\", \"doesn\", \"doing\", \"don\", \n",
    "    \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"hadn\", \"has\", \"hasn\", \"have\", \n",
    "    \"haven\", \"having\", \"he\", \"her\", \"here\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \n",
    "    \"i\", \"if\", \"in\", \"into\", \"is\", \"isn\", \"it\", \"itself\", \"just\", \"ll\", \"m\", \"ma\", \"me\", \"mightn\", \n",
    "    \"more\", \"most\", \"mustn\", \"my\", \"myself\", \"needn\", \"no\", \"nor\", \"not\", \"now\", \"o\", \"of\", \"off\", \n",
    "    \"on\", \"once\", \"only\", \"or\", \"other\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"re\", \n",
    "    \"s\", \"same\", \"shan\", \"she\", \"should\", \"shouldn\", \"so\", \"some\", \"such\", \"t\", \"than\", \"that\", \n",
    "    \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"these\", \"they\", \"this\", \n",
    "    \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"ve\", \"very\", \"was\", \"wasn\", \"we\", \n",
    "    \"were\", \"weren\", \"what\", \"when\", \"where\", \"which\", \"while\", \"who\", \"whom\", \"why\", \"will\", \n",
    "    \"with\", \"wouldn\", \"y\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\",\"gutenberg\",\"ebook\",\n",
    "    \"author\",\"ebooks\",\"illustrated\",\"illustrated\",\"manuscript\",\"literature\",\"book\",\"proofreading\",\n",
    "    \"books\",\"illustrations\",\"project\",\"online\",\"edition\",\"title\",\"release\",\"rights\",\"reserved\",\n",
    "    \"editions\",\"edition\",\"chapter\",\"chapters\",\"contents\",\"contents\",\"table\",\"contents\",\"table\",\n",
    "    \"proofreaders\",\"_italic\",\"italic\",\"punctuation\",\"punctuation\",\"transcriber\",\"pretext\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dorothy', 0.4767), ('oz', 0.4539), ('scarecrows', 0.4238), ('grimm', 0.4144), ('folklore', 0.4092), ('tales', 0.3862), ('wizard', 0.365), ('witches', 0.3642), ('glinda', 0.3557), ('lion', 0.3339)]\n"
     ]
    }
   ],
   "source": [
    "kw_model = KeyBERT()\n",
    "keywordsKeybert = kw_model.extract_keywords(text, keyphrase_ngram_range=(1,1), diversity=0.2,top_n=5,stop_words=stop_words,use_maxsum=True,use_mmr=True)\n",
    "print(keywordsKeybert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_paragraphs = findRelevantParagraphs(paragraphs,keywordsKeybert,text,kw_model,stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_paragraphs = sorted(relevant_paragraphs, key=lambda p: sum([1 for keyword in keywordsKeybert if keyword[0] in p]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name C:\\Users\\xraef/.cache\\torch\\sentence_transformers\\roberta-base. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at C:\\Users\\xraef/.cache\\torch\\sentence_transformers\\roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = 'roberta-base'\n",
    "keybert_model = KeyBERT(model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords: (('civilized countries', 0.9152), ('sorceresses', 0.9), ('witches', 0.8938), ('wizards', 0.8897), ('magicians', 0.8827))\n",
      "Paragraph: “Oh, yes,” replied Dorothy.\n",
      "“Then that accounts for it. In the civilized countries I believe there\n",
      "are no witches left, nor wizards, nor sorceresses, nor magicians. But,\n",
      "you see, the Land of Oz has never been civilized, for we are cut off\n",
      "from all the rest of the world. Therefore we still have witches and\n",
      "wizards amongst us.”\n",
      "\n",
      "Keywords: (('old time fairy tale', 0.9294), ('other human creations', 0.9201), ('fairy tales', 0.9168), ('instinctive love', 0.9165), ('disagreeable incident', 0.9095))\n",
      "Paragraph: Introduction\n",
      "Folklore, legends, myths and fairy tales have followed childhood\n",
      "through the ages, for every healthy youngster has a wholesome and\n",
      "instinctive love for stories fantastic, marvelous and manifestly\n",
      "unreal. The winged fairies of Grimm and Andersen have brought more\n",
      "happiness to childish hearts than all other human creations.\n",
      "Yet the old time fairy tale, having served for generations, may now be\n",
      "classed as “historical” in the children’s library; for the time has\n",
      "come for a series of newer “wonder tales” in which the stereotyped\n",
      "genie, dwarf and fairy are eliminated, together with all the horrible\n",
      "and blood-curdling incidents devised by their authors to point a\n",
      "fearsome moral to each tale. Modern education includes morality;\n",
      "therefore the modern child seeks only entertainment in its wonder tales\n",
      "and gladly dispenses with all disagreeable incident.\n",
      "\n",
      "Keywords: (('scarecrow', 0.9028), ('scarecrows', 0.9015), ('fence', 0.8724), ('wink', 0.8653), ('friendly way', 0.8651))\n",
      "Paragraph: While Dorothy was looking earnestly into the queer, painted face of the\n",
      "Scarecrow, she was surprised to see one of the eyes slowly wink at her.\n",
      "She thought she must have been mistaken at first, for none of the\n",
      "scarecrows in Kansas ever wink; but presently the figure nodded its\n",
      "head to her in a friendly way. Then she climbed down from the fence and\n",
      "walked up to it, while Toto ran around the pole and barked.\n",
      "\n",
      "Keywords: (('scarecrow', 0.9049), ('scarecrows', 0.9044), ('crows', 0.875), ('king crow', 0.869), ('nearer', 0.8646))\n",
      "Paragraph: But the Scarecrow said, “This is my battle, so lie down beside me and\n",
      "you will not be harmed.”\n",
      "So they all lay upon the ground except the Scarecrow, and he stood up\n",
      "and stretched out his arms. And when the crows saw him they were\n",
      "frightened, as these birds always are by scarecrows, and did not dare\n",
      "to come any nearer. But the King Crow said:\n",
      "“It is only a stuffed man. I will peck his eyes out.”\n",
      "\n",
      "Keywords: (('moment', 0.88), ('other lions', 0.8761), ('lion', 0.8689), ('enemy', 0.8439), ('end', 0.838))\n",
      "Paragraph: The Lion thought for a moment.\n",
      "“Are there any other lions in this forest?” he asked.\n",
      "“No; there were some, but the monster has eaten them all. And, besides,\n",
      "they were none of them nearly so large and brave as you.”\n",
      "“If I put an end to your enemy, will you bow down to me and obey me as\n",
      "King of the Forest?” inquired the Lion.\n",
      "\n",
      "Keywords: (('scarecrow', 0.9129), ('wild beasts', 0.8844), ('lion', 0.8801), ('dorothy', 0.8759), ('toto', 0.8746))\n",
      "Paragraph: “Perhaps there are wild beasts in the forest now,” said Dorothy.\n",
      "“I suppose there are,” returned the Lion, “but I do not see any of them\n",
      "about.”\n",
      "They walked through the forest until it became too dark to go any\n",
      "farther. Dorothy and Toto and the Lion lay down to sleep, while the\n",
      "Woodman and the Scarecrow kept watch over them as usual.\n",
      "\n",
      "Keywords: (('great assemblage', 0.9114), ('trouble', 0.8943), ('welcome', 0.8929), ('beasts', 0.8876), ('good time', 0.8851))\n",
      "Paragraph: As he spoke several of the beasts caught sight of him, and at once the\n",
      "great assemblage hushed as if by magic. The biggest of the tigers came\n",
      "up to the Lion and bowed, saying:\n",
      "“Welcome, O King of Beasts! You have come in good time to fight our\n",
      "enemy and bring peace to all the animals of the forest once more.”\n",
      "“What is your trouble?” asked the Lion quietly.\n",
      "\n",
      "Keywords: (('beasts', 0.8905), ('lion', 0.8744), ('dorothy', 0.8733), ('kansas', 0.8715), ('enemy', 0.8519))\n",
      "Paragraph: The Lion went back to the opening where the beasts of the forest were\n",
      "waiting for him and said proudly:\n",
      "“You need fear your enemy no longer.”\n",
      "Then the beasts bowed down to the Lion as their King, and he promised\n",
      "to come back and rule over them as soon as Dorothy was safely on her\n",
      "way to Kansas.\n",
      "\n",
      "Keywords: (('shaggy lion', 0.9163), ('beasts', 0.8849), ('dorothy', 0.8708), ('own home', 0.8592), ('life', 0.8524))\n",
      "Paragraph: Then the Witch looked at the big, shaggy Lion and asked, “When Dorothy\n",
      "has returned to her own home, what will become of you?”\n",
      "“Over the hill of the Hammer-Heads,” he answered, “lies a grand old\n",
      "forest, and all the beasts that live there have made me their King. If\n",
      "I could only get back to this forest, I would pass my life very happily\n",
      "there.”\n",
      "\n",
      "Keywords: (('good friends', 0.874), ('beast', 0.8735), ('good word', 0.8714), ('kingdom', 0.8707), ('coward', 0.8658))\n",
      "Paragraph: “And I should have lived a coward forever,” declared the Lion, “and no\n",
      "beast in all the forest would have had a good word to say to me.”\n",
      "“This is all true,” said Dorothy, “and I am glad I was of use to these\n",
      "good friends. But now that each of them has had what he most desired,\n",
      "and each is happy in having a kingdom to rule besides, I think I should\n",
      "like to go back to Kansas.”\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keyword_dict = {}\n",
    "\n",
    "for paragraph in relevant_paragraphs:\n",
    "    try:\n",
    "        keywordsRoberta = keybert_model.extract_keywords(paragraph, keyphrase_ngram_range=(1, 1), stop_words=stop_words, use_maxsum=True, top_n=5, use_mmr=True, diversity=0.2,vectorizer=KeyphraseCountVectorizer())\n",
    "    except:\n",
    "        keywordsRoberta = kw_model.extract_keywords(paragraph, keyphrase_ngram_range=(1, 1), stop_words=stop_words, use_maxsum=True, top_n=5, use_mmr=True, diversity=0.2,vectorizer=KeyphraseCountVectorizer())\n",
    "    \n",
    "    keyword_dict[tuple(keywordsRoberta)] = paragraph\n",
    "\n",
    "# Print the keywords and corresponding paragraphs\n",
    "for keywords, paragraph in keyword_dict.items():\n",
    "    print(\"Keywords:\", keywords)\n",
    "    print(\"Paragraph:\", paragraph)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['“', 'Oh', ',', 'yes', ',', '”', 'replied', 'Dorothy', '.', '“', 'Then', 'that', 'accounts', 'for', 'it', '.', 'In', 'the', 'civilized', 'countries', 'I', 'believe', 'there', 'are', 'no', 'witches', 'left', ',', 'nor', 'wizards', ',', 'nor', 'sorceresses', ',', 'nor', 'magicians', '.', 'But', ',', 'you', 'see', ',', 'the', 'Land', 'of', 'Oz', 'has', 'never', 'been', 'civilized', ',', 'for', 'we', 'are', 'cut', 'off', 'from', 'all', 'the', 'rest', 'of', 'the', 'world', '.', 'Therefore', 'we', 'still', 'have', 'witches', 'and', 'wizards', 'amongst', 'us', '.', '”']\n",
      "['Introduction', 'Folklore', ',', 'legends', ',', 'myths', 'and', 'fairy', 'tales', 'have', 'followed', 'childhood', 'through', 'the', 'ages', ',', 'for', 'every', 'healthy', 'youngster', 'has', 'a', 'wholesome', 'and', 'instinctive', 'love', 'for', 'stories', 'fantastic', ',', 'marvelous', 'and', 'manifestly', 'unreal', '.', 'The', 'winged', 'fairies', 'of', 'Grimm', 'and', 'Andersen', 'have', 'brought', 'more', 'happiness', 'to', 'childish', 'hearts', 'than', 'all', 'other', 'human', 'creations', '.', 'Yet', 'the', 'old', 'time', 'fairy', 'tale', ',', 'having', 'served', 'for', 'generations', ',', 'may', 'now', 'be', 'classed', 'as', '“', 'historical', '”', 'in', 'the', 'children', '’', 's', 'library', ';', 'for', 'the', 'time', 'has', 'come', 'for', 'a', 'series', 'of', 'newer', '“', 'wonder', 'tales', '”', 'in', 'which', 'the', 'stereotyped', 'genie', ',', 'dwarf', 'and', 'fairy', 'are', 'eliminated', ',', 'together', 'with', 'all', 'the', 'horrible', 'and', 'blood-curdling', 'incidents', 'devised', 'by', 'their', 'authors', 'to', 'point', 'a', 'fearsome', 'moral', 'to', 'each', 'tale', '.', 'Modern', 'education', 'includes', 'morality', ';', 'therefore', 'the', 'modern', 'child', 'seeks', 'only', 'entertainment', 'in', 'its', 'wonder', 'tales', 'and', 'gladly', 'dispenses', 'with', 'all', 'disagreeable', 'incident', '.']\n",
      "['While', 'Dorothy', 'was', 'looking', 'earnestly', 'into', 'the', 'queer', ',', 'painted', 'face', 'of', 'the', 'Scarecrow', ',', 'she', 'was', 'surprised', 'to', 'see', 'one', 'of', 'the', 'eyes', 'slowly', 'wink', 'at', 'her', '.', 'She', 'thought', 'she', 'must', 'have', 'been', 'mistaken', 'at', 'first', ',', 'for', 'none', 'of', 'the', 'scarecrows', 'in', 'Kansas', 'ever', 'wink', ';', 'but', 'presently', 'the', 'figure', 'nodded', 'its', 'head', 'to', 'her', 'in', 'a', 'friendly', 'way', '.', 'Then', 'she', 'climbed', 'down', 'from', 'the', 'fence', 'and', 'walked', 'up', 'to', 'it', ',', 'while', 'Toto', 'ran', 'around', 'the', 'pole', 'and', 'barked', '.']\n",
      "['But', 'the', 'Scarecrow', 'said', ',', '“', 'This', 'is', 'my', 'battle', ',', 'so', 'lie', 'down', 'beside', 'me', 'and', 'you', 'will', 'not', 'be', 'harmed.', '”', 'So', 'they', 'all', 'lay', 'upon', 'the', 'ground', 'except', 'the', 'Scarecrow', ',', 'and', 'he', 'stood', 'up', 'and', 'stretched', 'out', 'his', 'arms', '.', 'And', 'when', 'the', 'crows', 'saw', 'him', 'they', 'were', 'frightened', ',', 'as', 'these', 'birds', 'always', 'are', 'by', 'scarecrows', ',', 'and', 'did', 'not', 'dare', 'to', 'come', 'any', 'nearer', '.', 'But', 'the', 'King', 'Crow', 'said', ':', '“', 'It', 'is', 'only', 'a', 'stuffed', 'man', '.', 'I', 'will', 'peck', 'his', 'eyes', 'out', '.', '”']\n",
      "['The', 'Lion', 'thought', 'for', 'a', 'moment', '.', '“', 'Are', 'there', 'any', 'other', 'lions', 'in', 'this', 'forest', '?', '”', 'he', 'asked', '.', '“', 'No', ';', 'there', 'were', 'some', ',', 'but', 'the', 'monster', 'has', 'eaten', 'them', 'all', '.', 'And', ',', 'besides', ',', 'they', 'were', 'none', 'of', 'them', 'nearly', 'so', 'large', 'and', 'brave', 'as', 'you.', '”', '“', 'If', 'I', 'put', 'an', 'end', 'to', 'your', 'enemy', ',', 'will', 'you', 'bow', 'down', 'to', 'me', 'and', 'obey', 'me', 'as', 'King', 'of', 'the', 'Forest', '?', '”', 'inquired', 'the', 'Lion', '.']\n",
      "['“', 'Perhaps', 'there', 'are', 'wild', 'beasts', 'in', 'the', 'forest', 'now', ',', '”', 'said', 'Dorothy', '.', '“', 'I', 'suppose', 'there', 'are', ',', '”', 'returned', 'the', 'Lion', ',', '“', 'but', 'I', 'do', 'not', 'see', 'any', 'of', 'them', 'about.', '”', 'They', 'walked', 'through', 'the', 'forest', 'until', 'it', 'became', 'too', 'dark', 'to', 'go', 'any', 'farther', '.', 'Dorothy', 'and', 'Toto', 'and', 'the', 'Lion', 'lay', 'down', 'to', 'sleep', ',', 'while', 'the', 'Woodman', 'and', 'the', 'Scarecrow', 'kept', 'watch', 'over', 'them', 'as', 'usual', '.']\n",
      "['As', 'he', 'spoke', 'several', 'of', 'the', 'beasts', 'caught', 'sight', 'of', 'him', ',', 'and', 'at', 'once', 'the', 'great', 'assemblage', 'hushed', 'as', 'if', 'by', 'magic', '.', 'The', 'biggest', 'of', 'the', 'tigers', 'came', 'up', 'to', 'the', 'Lion', 'and', 'bowed', ',', 'saying', ':', '“', 'Welcome', ',', 'O', 'King', 'of', 'Beasts', '!', 'You', 'have', 'come', 'in', 'good', 'time', 'to', 'fight', 'our', 'enemy', 'and', 'bring', 'peace', 'to', 'all', 'the', 'animals', 'of', 'the', 'forest', 'once', 'more.', '”', '“', 'What', 'is', 'your', 'trouble', '?', '”', 'asked', 'the', 'Lion', 'quietly', '.']\n",
      "['The', 'Lion', 'went', 'back', 'to', 'the', 'opening', 'where', 'the', 'beasts', 'of', 'the', 'forest', 'were', 'waiting', 'for', 'him', 'and', 'said', 'proudly', ':', '“', 'You', 'need', 'fear', 'your', 'enemy', 'no', 'longer.', '”', 'Then', 'the', 'beasts', 'bowed', 'down', 'to', 'the', 'Lion', 'as', 'their', 'King', ',', 'and', 'he', 'promised', 'to', 'come', 'back', 'and', 'rule', 'over', 'them', 'as', 'soon', 'as', 'Dorothy', 'was', 'safely', 'on', 'her', 'way', 'to', 'Kansas', '.']\n",
      "['Then', 'the', 'Witch', 'looked', 'at', 'the', 'big', ',', 'shaggy', 'Lion', 'and', 'asked', ',', '“', 'When', 'Dorothy', 'has', 'returned', 'to', 'her', 'own', 'home', ',', 'what', 'will', 'become', 'of', 'you', '?', '”', '“', 'Over', 'the', 'hill', 'of', 'the', 'Hammer-Heads', ',', '”', 'he', 'answered', ',', '“', 'lies', 'a', 'grand', 'old', 'forest', ',', 'and', 'all', 'the', 'beasts', 'that', 'live', 'there', 'have', 'made', 'me', 'their', 'King', '.', 'If', 'I', 'could', 'only', 'get', 'back', 'to', 'this', 'forest', ',', 'I', 'would', 'pass', 'my', 'life', 'very', 'happily', 'there', '.', '”']\n",
      "['“', 'And', 'I', 'should', 'have', 'lived', 'a', 'coward', 'forever', ',', '”', 'declared', 'the', 'Lion', ',', '“', 'and', 'no', 'beast', 'in', 'all', 'the', 'forest', 'would', 'have', 'had', 'a', 'good', 'word', 'to', 'say', 'to', 'me.', '”', '“', 'This', 'is', 'all', 'true', ',', '”', 'said', 'Dorothy', ',', '“', 'and', 'I', 'am', 'glad', 'I', 'was', 'of', 'use', 'to', 'these', 'good', 'friends', '.', 'But', 'now', 'that', 'each', 'of', 'them', 'has', 'had', 'what', 'he', 'most', 'desired', ',', 'and', 'each', 'is', 'happy', 'in', 'having', 'a', 'kingdom', 'to', 'rule', 'besides', ',', 'I', 'think', 'I', 'should', 'like', 'to', 'go', 'back', 'to', 'Kansas', '.', '”']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\xraef\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the paragraphs into sentences\n",
    "nltk.download('punkt')\n",
    "\n",
    "sentences = []\n",
    "for para in relevant_paragraphs:\n",
    "    para_sentences = nltk.sent_tokenize(para)\n",
    "    sentences.append(para_sentences)\n",
    "\n",
    "# Tokenize the sentences into words\n",
    "words = []\n",
    "for sentence in sentences:\n",
    "    sentence_words = nltk.word_tokenize(\" \".join(sentence))\n",
    "    words.append(sentence_words)\n",
    "    print(sentence_words)\n",
    "\n",
    "# Output the words (including punctuation) in an array\n",
    "output_array = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
